{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxO5dfXc-1NA",
    "outputId": "601768bf-411a-47a4-88a3-3f2c0de2677c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Connecting to drive to obtain files, and to allow saving to drive\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "j5QLvPthhzXJ"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_roberta_new = pd.read_csv(\"/content/drive/MyDrive/RoBERTa_model/Train.csv\")\n",
    "validation_roberta = pd.read_csv(\"/content/drive/MyDrive/RoBERTa_model/Validation.csv\")\n",
    "test_roberta = pd.read_csv(\"/content/drive/MyDrive/RoBERTa_model/task_A_En_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "11uvPTj0-1NC",
    "outputId": "4d09828f-7da1-41a2-bf2d-a3cc2ce206aa"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"train_roberta_new\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 3462,\n        \"max\": 3467,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3463,\n          3467,\n          3465\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The population spike in Chicago in 9 months is about to be ridiculous\",\n          \"Overheard as my 13 year old games with a friend 'You smell like tartare sauce!' MontyPythonesqueDisses\",\n          \"Im finally surfacing after a holiday to Scotland and a difficult few days with an ill child (hopefully on the mend now). Happy September all! Smell the pencil shavings and that new notebook aroma. 1st Sept has always seemed a lot more promising than 1st January\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sarcastic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-5f13401d-dea6-45f5-a641-079f7fe9e5b2\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3117</th>\n",
       "      <td>3462</td>\n",
       "      <td>In case nobody is watching the MINNvsBAMA game...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3118</th>\n",
       "      <td>3463</td>\n",
       "      <td>The population spike in Chicago in 9 months is...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3119</th>\n",
       "      <td>3465</td>\n",
       "      <td>Im finally surfacing after a holiday to Scotla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3120</th>\n",
       "      <td>3466</td>\n",
       "      <td>Couldn't be prouder today. Well done to every ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3121</th>\n",
       "      <td>3467</td>\n",
       "      <td>Overheard as my 13 year old games with a frien...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f13401d-dea6-45f5-a641-079f7fe9e5b2')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-5f13401d-dea6-45f5-a641-079f7fe9e5b2 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-5f13401d-dea6-45f5-a641-079f7fe9e5b2');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-c05d218e-3254-4645-8dd4-8f5c3dbf3a9c\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c05d218e-3254-4645-8dd4-8f5c3dbf3a9c')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-c05d218e-3254-4645-8dd4-8f5c3dbf3a9c button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "      Unnamed: 0                                              tweet  sarcastic\n",
       "3117        3462  In case nobody is watching the MINNvsBAMA game...          0\n",
       "3118        3463  The population spike in Chicago in 9 months is...          0\n",
       "3119        3465  Im finally surfacing after a holiday to Scotla...          0\n",
       "3120        3466  Couldn't be prouder today. Well done to every ...          0\n",
       "3121        3467  Overheard as my 13 year old games with a frien...          0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspect training data\n",
    "train_roberta_new.head()\n",
    "train_roberta_new.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ff1z1_NV-1ND",
    "outputId": "deebe76c-002e-479c-e674-12323cc39cf6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"train_roberta_new\",\n  \"rows\": 3122,\n  \"fields\": [\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3109,\n        \"samples\": [\n          \"me trying to sleep slightly earlier than usual bc I feel like shit \\nmy friend, texting the group chat 13 separate times at nearly 4am hello I dont think so! how abt I tell u abt how bad things are going instead )\",\n          \"Blatantly obvious that Lionel Messi is now set for a move to Leeds.\\n\\nThe Newells old boys network.\",\n          \"Does anyone else have to listen to extremely high energy music in order to work or is that just me?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sarcastic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "train_roberta_new"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-2eff6de6-6f07-4322-944c-70271805da71\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today my pop-pop told me I was not forced to g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I did too, and I also reported Cancun Cruz ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2eff6de6-6f07-4322-944c-70271805da71')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-2eff6de6-6f07-4322-944c-70271805da71 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-2eff6de6-6f07-4322-944c-70271805da71');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-5a1fd575-1dda-433c-acf9-d1b9c662790a\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5a1fd575-1dda-433c-acf9-d1b9c662790a')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-5a1fd575-1dda-433c-acf9-d1b9c662790a button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                               tweet  sarcastic\n",
       "0  The only thing I got from college is a caffein...          1\n",
       "1  I love it when professors draw a big question ...          1\n",
       "2  Remember the hundred emails from companies whe...          1\n",
       "3  Today my pop-pop told me I was not forced to g...          1\n",
       "4     I did too, and I also reported Cancun Cruz ...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take only useful columns from train data (e.g. tweet and sarcastic)\n",
    "train_roberta_new = train_roberta_new[['tweet', 'sarcastic']]\n",
    "train_roberta_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JHXV13ASKtfV"
   },
   "outputs": [],
   "source": [
    "# train_roberta_new['tweet']\n",
    "train_roberta_new['tweet'] = train_roberta_new['tweet'].astype(str)\n",
    "validation_roberta['tweet'] = validation_roberta['tweet'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XaVdDxTI-1NF"
   },
   "outputs": [],
   "source": [
    "#clean text function\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str): # ensures text is a string before cleaning\n",
    "        text = re.sub(r'@[A-Za-z0-9]+', '', text)\n",
    "        text = re.sub(r'#', '', text)\n",
    "        text = re.sub(r'RT[\\s]+', '', text)\n",
    "        text = re.sub(r'https?:\\/\\/\\S+', '', text)\n",
    "        text = re.sub(r':', '', text)\n",
    "        text = re.sub(r'‚Ä¶', '', text)\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "        return text\n",
    "    # if text is not a string, return an empty string\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "v5o9GVga-1NG"
   },
   "outputs": [],
   "source": [
    "#apply clean text to train, validation and test data\n",
    "train_roberta_new['tweet'] = train_roberta_new['tweet'].apply(clean_text)\n",
    "validation_roberta['tweet'] = validation_roberta['tweet'].apply(clean_text)\n",
    "test_roberta['text'] = test_roberta['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "J2KTCpFNKLcS"
   },
   "outputs": [],
   "source": [
    "#split X and y for all sets\n",
    "X_train = train_roberta_new['tweet']\n",
    "y_train = train_roberta_new['sarcastic']\n",
    "\n",
    "X_val = validation_roberta['tweet']\n",
    "y_val = validation_roberta['sarcastic']\n",
    "\n",
    "X_test = test_roberta['text']\n",
    "y_test = test_roberta['sarcastic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vp60ybWTLmsK"
   },
   "outputs": [],
   "source": [
    "#perform oversampling on training set\n",
    "#(not on validation or test; validation should reflect test set, and test set shouldn't be resampled)\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# needed to reshape X_train so that it has the appropriate format\n",
    "X_train_for_oversampling = X_train.values.reshape(-1,1)\n",
    "\n",
    "rosy = RandomOverSampler(random_state = 42)\n",
    "X_train_resampled, y_train_resampled = rosy.fit_resample(X_train_for_oversampling, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pnGtJweiHOHZ",
    "outputId": "26580404-cafd-4ab6-af14-f5ce97014794"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "(3122,)\n"
     ]
    }
   ],
   "source": [
    "# Check the original datatype and shape\n",
    "print(type(X_train))  \n",
    "print(X_train.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tftSWY2tHC4T",
    "outputId": "657b66b1-37a2-446e-d945-207bafd8d846"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "0    The only thing I got from college is a caffein...\n",
      "1    I love it when professors draw a big question ...\n",
      "2    Remember the hundred emails from companies whe...\n",
      "3    Today my pop-pop told me I was not forced to g...\n",
      "4       I did too, and I also reported Cancun Cruz ...\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert the DataFrame back to Series, so it has the right format for \n",
    "X_train_resampled = pd.Series(X_train_resampled.squeeze(), name=X_train.name)\n",
    "\n",
    "# Verify the result\n",
    "print(type(X_train_resampled)) \n",
    "print(X_train_resampled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dKmNTxZ8-1NH",
    "outputId": "048bf0cc-9a32-407a-9072-ba7537da0ac7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "from transformers import RobertaTokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Tokenize train, validation and test data\n",
    "train_encodings = tokenizer(X_train_resampled.tolist(), truncation=True, padding=True)\n",
    "val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(X_test.tolist(), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Q9nuiFG4-1NI"
   },
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "import torch\n",
    "\n",
    "class sarcasmDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = sarcasmDataset(train_encodings, y_train_resampled)\n",
    "val_dataset = sarcasmDataset(val_encodings, y_val)\n",
    "test_dataset = sarcasmDataset(test_encodings, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LtW0oqJ_CI2t",
    "outputId": "6ca847d3-172b-4a8d-a151-325c0e905445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting datasets>=2.0.0 (from evaluate)\n",
      "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n",
      "Collecting dill (from evaluate)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.4)\n",
      "Collecting xxhash (from evaluate)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess (from evaluate)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.23.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.14.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: xxhash, dill, multiprocess, datasets, evaluate\n",
      "Successfully installed datasets-2.19.1 dill-0.3.8 evaluate-0.4.2 multiprocess-0.70.16 xxhash-3.4.1\n"
     ]
    }
   ],
   "source": [
    "# Needed to get accuracy\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jZy4FJlPTOpo",
    "outputId": "53b67870-edc9-4e87-9846-070e59853fcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
      "Successfully installed accelerate-0.30.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.41.1-py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.41.0\n",
      "    Uninstalling transformers-4.41.0:\n",
      "      Successfully uninstalled transformers-4.41.0\n",
      "Successfully installed transformers-4.41.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "66b3581763f64c478d9b44aa70482e4b",
       "pip_warning": {
        "packages": [
         "transformers"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "#session needs to be restarted after running this\n",
    "\n",
    "!pip install --upgrade accelerate\n",
    "!pip install --upgrade transformers\n",
    "!pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "a54fb74976ac427bbefb217e05a16206",
      "e88bfd8d58284ef2a0c275785560cf6d",
      "637139d664794d2686f3ed73fdbc45af",
      "26dc030b6f5d402d8a8ad55ff8b9cf01",
      "21d51664395a458cad817feef13e49da",
      "6688bb15831d4869b02547d4a932ab1e",
      "3a51d209541442148ba79e689bf3f78b",
      "af0f9d8b78c54fe68b08e96682226a8a",
      "cdafcb633bdb46af964264385e3b5519",
      "508e8beb44a645dd8eaaf1935c6671d2",
      "58e96e7b461c4beeba28045c2be967d6"
     ]
    },
    "id": "lo4sSeh9-1NJ",
    "outputId": "1558f626-bec5-467c-f740-44b5bfc27eb7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54fb74976ac427bbefb217e05a16206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='885' max='885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [885/885 6:46:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.696100</td>\n",
       "      <td>0.683205</td>\n",
       "      <td>0.710983</td>\n",
       "      <td>0.505496</td>\n",
       "      <td>0.710983</td>\n",
       "      <td>0.590884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.693800</td>\n",
       "      <td>0.682277</td>\n",
       "      <td>0.710983</td>\n",
       "      <td>0.505496</td>\n",
       "      <td>0.710983</td>\n",
       "      <td>0.590884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.695500</td>\n",
       "      <td>0.679353</td>\n",
       "      <td>0.710983</td>\n",
       "      <td>0.505496</td>\n",
       "      <td>0.710983</td>\n",
       "      <td>0.590884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.698000</td>\n",
       "      <td>0.680724</td>\n",
       "      <td>0.710983</td>\n",
       "      <td>0.505496</td>\n",
       "      <td>0.710983</td>\n",
       "      <td>0.590884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.695500</td>\n",
       "      <td>0.686135</td>\n",
       "      <td>0.713873</td>\n",
       "      <td>0.700523</td>\n",
       "      <td>0.713873</td>\n",
       "      <td>0.602704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.693500</td>\n",
       "      <td>0.687216</td>\n",
       "      <td>0.716763</td>\n",
       "      <td>0.685487</td>\n",
       "      <td>0.716763</td>\n",
       "      <td>0.622793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.690500</td>\n",
       "      <td>0.690098</td>\n",
       "      <td>0.621387</td>\n",
       "      <td>0.629185</td>\n",
       "      <td>0.621387</td>\n",
       "      <td>0.625057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.696700</td>\n",
       "      <td>0.691160</td>\n",
       "      <td>0.557803</td>\n",
       "      <td>0.623680</td>\n",
       "      <td>0.557803</td>\n",
       "      <td>0.577664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.689300</td>\n",
       "      <td>0.688658</td>\n",
       "      <td>0.641618</td>\n",
       "      <td>0.619692</td>\n",
       "      <td>0.641618</td>\n",
       "      <td>0.628708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.690500</td>\n",
       "      <td>0.694700</td>\n",
       "      <td>0.479769</td>\n",
       "      <td>0.703725</td>\n",
       "      <td>0.479769</td>\n",
       "      <td>0.475804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.686100</td>\n",
       "      <td>0.707654</td>\n",
       "      <td>0.306358</td>\n",
       "      <td>0.795988</td>\n",
       "      <td>0.306358</td>\n",
       "      <td>0.165228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.686200</td>\n",
       "      <td>0.691256</td>\n",
       "      <td>0.540462</td>\n",
       "      <td>0.670877</td>\n",
       "      <td>0.540462</td>\n",
       "      <td>0.558209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.696800</td>\n",
       "      <td>0.686411</td>\n",
       "      <td>0.595376</td>\n",
       "      <td>0.658726</td>\n",
       "      <td>0.595376</td>\n",
       "      <td>0.613444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.675700</td>\n",
       "      <td>0.704857</td>\n",
       "      <td>0.447977</td>\n",
       "      <td>0.658259</td>\n",
       "      <td>0.447977</td>\n",
       "      <td>0.443036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.688700</td>\n",
       "      <td>0.615316</td>\n",
       "      <td>0.713873</td>\n",
       "      <td>0.682149</td>\n",
       "      <td>0.713873</td>\n",
       "      <td>0.607588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.660400</td>\n",
       "      <td>0.700017</td>\n",
       "      <td>0.514451</td>\n",
       "      <td>0.683413</td>\n",
       "      <td>0.514451</td>\n",
       "      <td>0.525560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.656900</td>\n",
       "      <td>0.611288</td>\n",
       "      <td>0.667630</td>\n",
       "      <td>0.615360</td>\n",
       "      <td>0.667630</td>\n",
       "      <td>0.628754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.707000</td>\n",
       "      <td>0.698065</td>\n",
       "      <td>0.520231</td>\n",
       "      <td>0.674608</td>\n",
       "      <td>0.520231</td>\n",
       "      <td>0.534283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.658500</td>\n",
       "      <td>0.673757</td>\n",
       "      <td>0.601156</td>\n",
       "      <td>0.707150</td>\n",
       "      <td>0.601156</td>\n",
       "      <td>0.619083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.629100</td>\n",
       "      <td>0.728963</td>\n",
       "      <td>0.543353</td>\n",
       "      <td>0.697828</td>\n",
       "      <td>0.543353</td>\n",
       "      <td>0.557388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.661500</td>\n",
       "      <td>0.602385</td>\n",
       "      <td>0.676301</td>\n",
       "      <td>0.696327</td>\n",
       "      <td>0.676301</td>\n",
       "      <td>0.684156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.667800</td>\n",
       "      <td>0.613535</td>\n",
       "      <td>0.656069</td>\n",
       "      <td>0.684533</td>\n",
       "      <td>0.656069</td>\n",
       "      <td>0.666538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.646000</td>\n",
       "      <td>0.576209</td>\n",
       "      <td>0.687861</td>\n",
       "      <td>0.664737</td>\n",
       "      <td>0.687861</td>\n",
       "      <td>0.672374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.603300</td>\n",
       "      <td>0.677662</td>\n",
       "      <td>0.601156</td>\n",
       "      <td>0.703932</td>\n",
       "      <td>0.601156</td>\n",
       "      <td>0.619260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.755700</td>\n",
       "      <td>0.610703</td>\n",
       "      <td>0.702312</td>\n",
       "      <td>0.689671</td>\n",
       "      <td>0.702312</td>\n",
       "      <td>0.694647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.670100</td>\n",
       "      <td>0.595621</td>\n",
       "      <td>0.722543</td>\n",
       "      <td>0.688068</td>\n",
       "      <td>0.722543</td>\n",
       "      <td>0.673228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.653700</td>\n",
       "      <td>0.606493</td>\n",
       "      <td>0.702312</td>\n",
       "      <td>0.688067</td>\n",
       "      <td>0.702312</td>\n",
       "      <td>0.693456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.551200</td>\n",
       "      <td>0.618180</td>\n",
       "      <td>0.673410</td>\n",
       "      <td>0.710162</td>\n",
       "      <td>0.673410</td>\n",
       "      <td>0.685225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.478400</td>\n",
       "      <td>0.685680</td>\n",
       "      <td>0.710983</td>\n",
       "      <td>0.676537</td>\n",
       "      <td>0.710983</td>\n",
       "      <td>0.678194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.591000</td>\n",
       "      <td>0.744204</td>\n",
       "      <td>0.604046</td>\n",
       "      <td>0.693074</td>\n",
       "      <td>0.604046</td>\n",
       "      <td>0.622493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.494200</td>\n",
       "      <td>0.610933</td>\n",
       "      <td>0.670520</td>\n",
       "      <td>0.676434</td>\n",
       "      <td>0.670520</td>\n",
       "      <td>0.673285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.516100</td>\n",
       "      <td>0.646971</td>\n",
       "      <td>0.650289</td>\n",
       "      <td>0.705199</td>\n",
       "      <td>0.650289</td>\n",
       "      <td>0.665358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.438100</td>\n",
       "      <td>0.612974</td>\n",
       "      <td>0.690751</td>\n",
       "      <td>0.691671</td>\n",
       "      <td>0.690751</td>\n",
       "      <td>0.691206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.517500</td>\n",
       "      <td>0.563419</td>\n",
       "      <td>0.751445</td>\n",
       "      <td>0.733576</td>\n",
       "      <td>0.751445</td>\n",
       "      <td>0.717771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.499800</td>\n",
       "      <td>0.600905</td>\n",
       "      <td>0.713873</td>\n",
       "      <td>0.709717</td>\n",
       "      <td>0.713873</td>\n",
       "      <td>0.711644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.564400</td>\n",
       "      <td>0.675861</td>\n",
       "      <td>0.638728</td>\n",
       "      <td>0.712888</td>\n",
       "      <td>0.638728</td>\n",
       "      <td>0.655472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.419500</td>\n",
       "      <td>0.577170</td>\n",
       "      <td>0.710983</td>\n",
       "      <td>0.696597</td>\n",
       "      <td>0.710983</td>\n",
       "      <td>0.701791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.411200</td>\n",
       "      <td>0.831425</td>\n",
       "      <td>0.641618</td>\n",
       "      <td>0.729089</td>\n",
       "      <td>0.641618</td>\n",
       "      <td>0.658333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.497400</td>\n",
       "      <td>0.600342</td>\n",
       "      <td>0.702312</td>\n",
       "      <td>0.712415</td>\n",
       "      <td>0.702312</td>\n",
       "      <td>0.706668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.464500</td>\n",
       "      <td>0.687863</td>\n",
       "      <td>0.650289</td>\n",
       "      <td>0.705199</td>\n",
       "      <td>0.650289</td>\n",
       "      <td>0.665358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.378800</td>\n",
       "      <td>0.668031</td>\n",
       "      <td>0.693642</td>\n",
       "      <td>0.677944</td>\n",
       "      <td>0.693642</td>\n",
       "      <td>0.683898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.470600</td>\n",
       "      <td>0.721905</td>\n",
       "      <td>0.708092</td>\n",
       "      <td>0.677154</td>\n",
       "      <td>0.708092</td>\n",
       "      <td>0.681684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.391900</td>\n",
       "      <td>0.697019</td>\n",
       "      <td>0.708092</td>\n",
       "      <td>0.673199</td>\n",
       "      <td>0.708092</td>\n",
       "      <td>0.675984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.436600</td>\n",
       "      <td>0.653056</td>\n",
       "      <td>0.710983</td>\n",
       "      <td>0.714470</td>\n",
       "      <td>0.710983</td>\n",
       "      <td>0.712632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.460700</td>\n",
       "      <td>0.708428</td>\n",
       "      <td>0.661850</td>\n",
       "      <td>0.694542</td>\n",
       "      <td>0.661850</td>\n",
       "      <td>0.673170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.422700</td>\n",
       "      <td>0.666920</td>\n",
       "      <td>0.667630</td>\n",
       "      <td>0.695578</td>\n",
       "      <td>0.667630</td>\n",
       "      <td>0.677747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.378300</td>\n",
       "      <td>0.739034</td>\n",
       "      <td>0.653179</td>\n",
       "      <td>0.682888</td>\n",
       "      <td>0.653179</td>\n",
       "      <td>0.664011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.301300</td>\n",
       "      <td>0.793879</td>\n",
       "      <td>0.716763</td>\n",
       "      <td>0.702815</td>\n",
       "      <td>0.716763</td>\n",
       "      <td>0.707755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.592700</td>\n",
       "      <td>0.784772</td>\n",
       "      <td>0.690751</td>\n",
       "      <td>0.695401</td>\n",
       "      <td>0.690751</td>\n",
       "      <td>0.692935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.507600</td>\n",
       "      <td>0.660475</td>\n",
       "      <td>0.705202</td>\n",
       "      <td>0.712411</td>\n",
       "      <td>0.705202</td>\n",
       "      <td>0.708435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.474100</td>\n",
       "      <td>0.633086</td>\n",
       "      <td>0.687861</td>\n",
       "      <td>0.705369</td>\n",
       "      <td>0.687861</td>\n",
       "      <td>0.694821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.255700</td>\n",
       "      <td>0.803449</td>\n",
       "      <td>0.734104</td>\n",
       "      <td>0.707795</td>\n",
       "      <td>0.734104</td>\n",
       "      <td>0.700101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.384000</td>\n",
       "      <td>0.946483</td>\n",
       "      <td>0.641618</td>\n",
       "      <td>0.669611</td>\n",
       "      <td>0.641618</td>\n",
       "      <td>0.652236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.497100</td>\n",
       "      <td>0.659283</td>\n",
       "      <td>0.682081</td>\n",
       "      <td>0.678334</td>\n",
       "      <td>0.682081</td>\n",
       "      <td>0.680119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.430800</td>\n",
       "      <td>0.715413</td>\n",
       "      <td>0.725434</td>\n",
       "      <td>0.699282</td>\n",
       "      <td>0.725434</td>\n",
       "      <td>0.700594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>0.814189</td>\n",
       "      <td>0.682081</td>\n",
       "      <td>0.708289</td>\n",
       "      <td>0.682081</td>\n",
       "      <td>0.691499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.404000</td>\n",
       "      <td>0.843222</td>\n",
       "      <td>0.739884</td>\n",
       "      <td>0.736848</td>\n",
       "      <td>0.739884</td>\n",
       "      <td>0.674530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.550200</td>\n",
       "      <td>0.662871</td>\n",
       "      <td>0.708092</td>\n",
       "      <td>0.703842</td>\n",
       "      <td>0.708092</td>\n",
       "      <td>0.705818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.303200</td>\n",
       "      <td>0.635891</td>\n",
       "      <td>0.699422</td>\n",
       "      <td>0.706748</td>\n",
       "      <td>0.699422</td>\n",
       "      <td>0.702718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.162300</td>\n",
       "      <td>0.829372</td>\n",
       "      <td>0.736994</td>\n",
       "      <td>0.713479</td>\n",
       "      <td>0.736994</td>\n",
       "      <td>0.711547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>1.054981</td>\n",
       "      <td>0.734104</td>\n",
       "      <td>0.708073</td>\n",
       "      <td>0.734104</td>\n",
       "      <td>0.702053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.335900</td>\n",
       "      <td>1.122315</td>\n",
       "      <td>0.702312</td>\n",
       "      <td>0.686479</td>\n",
       "      <td>0.702312</td>\n",
       "      <td>0.692222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.138600</td>\n",
       "      <td>1.000443</td>\n",
       "      <td>0.736994</td>\n",
       "      <td>0.716098</td>\n",
       "      <td>0.736994</td>\n",
       "      <td>0.717833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.147300</td>\n",
       "      <td>1.169403</td>\n",
       "      <td>0.710983</td>\n",
       "      <td>0.699622</td>\n",
       "      <td>0.710983</td>\n",
       "      <td>0.704104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.279500</td>\n",
       "      <td>1.289395</td>\n",
       "      <td>0.748555</td>\n",
       "      <td>0.730234</td>\n",
       "      <td>0.748555</td>\n",
       "      <td>0.711495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>1.196112</td>\n",
       "      <td>0.713873</td>\n",
       "      <td>0.711358</td>\n",
       "      <td>0.713873</td>\n",
       "      <td>0.712561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.300500</td>\n",
       "      <td>1.135002</td>\n",
       "      <td>0.731214</td>\n",
       "      <td>0.704718</td>\n",
       "      <td>0.731214</td>\n",
       "      <td>0.701649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.270300</td>\n",
       "      <td>1.057129</td>\n",
       "      <td>0.690751</td>\n",
       "      <td>0.697296</td>\n",
       "      <td>0.690751</td>\n",
       "      <td>0.693749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.255500</td>\n",
       "      <td>0.949619</td>\n",
       "      <td>0.728324</td>\n",
       "      <td>0.699891</td>\n",
       "      <td>0.728324</td>\n",
       "      <td>0.695576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.110700</td>\n",
       "      <td>1.041450</td>\n",
       "      <td>0.705202</td>\n",
       "      <td>0.714283</td>\n",
       "      <td>0.705202</td>\n",
       "      <td>0.709163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>1.127036</td>\n",
       "      <td>0.736994</td>\n",
       "      <td>0.715453</td>\n",
       "      <td>0.736994</td>\n",
       "      <td>0.686510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.176500</td>\n",
       "      <td>1.116967</td>\n",
       "      <td>0.719653</td>\n",
       "      <td>0.712482</td>\n",
       "      <td>0.719653</td>\n",
       "      <td>0.715566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.186600</td>\n",
       "      <td>1.175640</td>\n",
       "      <td>0.719653</td>\n",
       "      <td>0.689904</td>\n",
       "      <td>0.719653</td>\n",
       "      <td>0.690704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.141400</td>\n",
       "      <td>1.144146</td>\n",
       "      <td>0.731214</td>\n",
       "      <td>0.712030</td>\n",
       "      <td>0.731214</td>\n",
       "      <td>0.715903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>1.223993</td>\n",
       "      <td>0.731214</td>\n",
       "      <td>0.710045</td>\n",
       "      <td>0.731214</td>\n",
       "      <td>0.713105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>1.109261</td>\n",
       "      <td>0.734104</td>\n",
       "      <td>0.708442</td>\n",
       "      <td>0.734104</td>\n",
       "      <td>0.703938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.082400</td>\n",
       "      <td>1.064691</td>\n",
       "      <td>0.728324</td>\n",
       "      <td>0.704248</td>\n",
       "      <td>0.728324</td>\n",
       "      <td>0.706200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.249300</td>\n",
       "      <td>1.123195</td>\n",
       "      <td>0.719653</td>\n",
       "      <td>0.690887</td>\n",
       "      <td>0.719653</td>\n",
       "      <td>0.692528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.086200</td>\n",
       "      <td>1.176970</td>\n",
       "      <td>0.734104</td>\n",
       "      <td>0.707795</td>\n",
       "      <td>0.734104</td>\n",
       "      <td>0.700101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.169100</td>\n",
       "      <td>1.226724</td>\n",
       "      <td>0.739884</td>\n",
       "      <td>0.717989</td>\n",
       "      <td>0.739884</td>\n",
       "      <td>0.717149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>1.290515</td>\n",
       "      <td>0.736994</td>\n",
       "      <td>0.713479</td>\n",
       "      <td>0.736994</td>\n",
       "      <td>0.711547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>1.456623</td>\n",
       "      <td>0.739884</td>\n",
       "      <td>0.721772</td>\n",
       "      <td>0.739884</td>\n",
       "      <td>0.688678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>1.384868</td>\n",
       "      <td>0.742775</td>\n",
       "      <td>0.720696</td>\n",
       "      <td>0.742775</td>\n",
       "      <td>0.716213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.201800</td>\n",
       "      <td>1.396633</td>\n",
       "      <td>0.739884</td>\n",
       "      <td>0.719234</td>\n",
       "      <td>0.739884</td>\n",
       "      <td>0.720203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.203400</td>\n",
       "      <td>1.403643</td>\n",
       "      <td>0.736994</td>\n",
       "      <td>0.714658</td>\n",
       "      <td>0.736994</td>\n",
       "      <td>0.714798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.094300</td>\n",
       "      <td>1.417344</td>\n",
       "      <td>0.734104</td>\n",
       "      <td>0.712197</td>\n",
       "      <td>0.734104</td>\n",
       "      <td>0.713985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.199500</td>\n",
       "      <td>1.409361</td>\n",
       "      <td>0.734104</td>\n",
       "      <td>0.711413</td>\n",
       "      <td>0.734104</td>\n",
       "      <td>0.712451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.086800</td>\n",
       "      <td>1.409411</td>\n",
       "      <td>0.731214</td>\n",
       "      <td>0.707426</td>\n",
       "      <td>0.731214</td>\n",
       "      <td>0.708530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=885, training_loss=0.4292625893307271, metrics={'train_runtime': 24409.9823, 'train_samples_per_second': 0.579, 'train_steps_per_second': 0.036, 'total_flos': 994791039211800.0, 'train_loss': 0.4292625893307271, 'epoch': 3.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading, instantiating and training the model\n",
    "\n",
    "from transformers import RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import TrainerCallback\n",
    "import evaluate\n",
    "from datasets import load_metric\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Loading pretrained model\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "\n",
    "# Function that gives the evaluation metrics\n",
    "def compute_metrics2(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # computing metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision = precision_score(labels, predictions, average='weighted')\n",
    "    recall = recall_score(labels, predictions, average='weighted')\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "\n",
    "    return {\n",
    "      \"accuracy\": accuracy,\n",
    "      \"precision\": precision,\n",
    "      \"recall\": recall,\n",
    "      \"f1\": f1\n",
    "    }\n",
    "\n",
    "# Defining the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    evaluation_strategy = \"steps\",\n",
    "    save_strategy = \"steps\",\n",
    "    logging_strategy=\"steps\",\n",
    ")\n",
    "\n",
    "# Defining the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,            # evaluation dataset\n",
    "    compute_metrics=compute_metrics2,\n",
    ")\n",
    "\n",
    "# Training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "id": "2yNZdwWbF5nv",
    "outputId": "c0ab0408-d31d-48c3-ea4b-2dfb7d13840f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:55]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6604750156402588,\n",
       " 'eval_accuracy': 0.7052023121387283,\n",
       " 'eval_precision': 0.7124111044546271,\n",
       " 'eval_recall': 0.7052023121387283,\n",
       " 'eval_f1': 0.7084351539159736,\n",
       " 'eval_runtime': 67.9976,\n",
       " 'eval_samples_per_second': 5.088,\n",
       " 'eval_steps_per_second': 0.088,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation metrics on the validation set\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "IC-EnPy-629B",
    "outputId": "241e4f75-2d26-4645-a86d-94e56a4b8a60"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 07:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 10:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6822778582572937,\n",
       " 'eval_accuracy': 0.7135714285714285,\n",
       " 'eval_precision': 0.8362754866676044,\n",
       " 'eval_recall': 0.7135714285714285,\n",
       " 'eval_f1': 0.7529731216368912,\n",
       " 'eval_runtime': 585.0613,\n",
       " 'eval_samples_per_second': 2.393,\n",
       " 'eval_steps_per_second': 0.038,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation metrics on the test set\n",
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "Tm_qJzSH1Ofs",
    "outputId": "b59f3c81-4459-45f5-e753-5433848008f7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.44080842,  0.36884162],\n",
       "       [ 0.9126409 , -0.8817768 ],\n",
       "       [-0.01099393, -0.0131508 ],\n",
       "       ...,\n",
       "       [ 1.030128  , -1.1494087 ],\n",
       "       [-1.4855938 ,  1.5275781 ],\n",
       "       [ 0.36402643, -0.3893823 ]], dtype=float32), label_ids=array([0, 0, 1, ..., 0, 1, 1]), metrics={'test_loss': 0.6822778582572937, 'test_accuracy': 0.7135714285714285, 'test_precision': 0.8362754866676044, 'test_recall': 0.7135714285714285, 'test_f1': 0.7529731216368912, 'test_runtime': 604.7392, 'test_samples_per_second': 2.315, 'test_steps_per_second': 0.036})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict function that gives its predictions for the test set, and the evaluation metrics of its performance on the test set\n",
    "trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jpbC7GuQkTXy"
   },
   "outputs": [],
   "source": [
    "# Saving the model to the drive\n",
    "trainer.save_model(\"/content/drive/MyDrive/RoBERTa_model\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "21d51664395a458cad817feef13e49da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26dc030b6f5d402d8a8ad55ff8b9cf01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_508e8beb44a645dd8eaaf1935c6671d2",
      "placeholder": "​",
      "style": "IPY_MODEL_58e96e7b461c4beeba28045c2be967d6",
      "value": " 499M/499M [00:03&lt;00:00, 162MB/s]"
     }
    },
    "3a51d209541442148ba79e689bf3f78b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "508e8beb44a645dd8eaaf1935c6671d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58e96e7b461c4beeba28045c2be967d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "637139d664794d2686f3ed73fdbc45af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af0f9d8b78c54fe68b08e96682226a8a",
      "max": 498818054,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cdafcb633bdb46af964264385e3b5519",
      "value": 498818054
     }
    },
    "6688bb15831d4869b02547d4a932ab1e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a54fb74976ac427bbefb217e05a16206": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e88bfd8d58284ef2a0c275785560cf6d",
       "IPY_MODEL_637139d664794d2686f3ed73fdbc45af",
       "IPY_MODEL_26dc030b6f5d402d8a8ad55ff8b9cf01"
      ],
      "layout": "IPY_MODEL_21d51664395a458cad817feef13e49da"
     }
    },
    "af0f9d8b78c54fe68b08e96682226a8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cdafcb633bdb46af964264385e3b5519": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e88bfd8d58284ef2a0c275785560cf6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6688bb15831d4869b02547d4a932ab1e",
      "placeholder": "​",
      "style": "IPY_MODEL_3a51d209541442148ba79e689bf3f78b",
      "value": "model.safetensors: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
